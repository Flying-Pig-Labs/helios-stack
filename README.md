# **Building the "Helios" Research Swarm: A Guide to Automated Deep Research with Claude Code Sub-Agents**

## **Introduction**

The landscape of software development and knowledge work is undergoing a fundamental transformation, shifting from single-shot, conversational interactions with AI to the deployment of sophisticated, multi-step agentic systems.1 Tools like Anthropic's Claude Code are at the vanguard of this evolution, offering capabilities that extend far beyond simple code completion. When leveraged to its full potential, Claude Code acts as a powerful, scriptable agent capable of executing complex, text-based workflows autonomously.4 This report details the design, architecture, and implementation of such a system: the Helios Research Swarm.

The Helios system represents a concrete implementation of this new agentic paradigm. It is a multi-agent framework designed to automate the entire cognitive lifecycle of deep research. Initiated by a single, high-level natural language prompt, Helios orchestrates a team of specialized AI agents to deconstruct the query, gather information, synthesize findings, and critically review the output. This automated pipeline is structured around five core phases: Decompose, Allocate, Execute, Synthesize, and Review. The objective is to delegate the laborious aspects of research to a reliable and scalable AI workforce, freeing human intellect for higher-order analysis and strategic direction. This document serves as a comprehensive technical guide for understanding, deploying, and extending the Helios Research Swarm.

## **Section 1: Architectural Blueprint of the Helios Swarm**

The efficacy of any multi-agent system hinges on a clear and robust architectural foundation. The Helios Swarm is built upon a set of deliberate design principles that prioritize durability, modularity, and scalability. This section outlines the core architectural model, the phased workflow, the state management strategy, and a visual representation of the system's operation.

### **1.1 The Orchestrator-Agent Model: A High-Level Overview**

The Helios Swarm employs a classic Orchestrator-Agent model, a design pattern well-suited for managing complex, distributed tasks. This architecture consists of two primary components:

* **The Orchestrator:** A central Python script (helios\_orchestrator.py) serves as the "brain" of the operation. It is responsible for interpreting the initial user request, decomposing it into a strategic plan, allocating tasks to individual agents, monitoring their progress, and assembling their outputs into a final, coherent product. The Orchestrator does not perform any research itself; its sole function is to manage the workflow and the agent swarm.  
* **The Agents:** A pool of headless Claude Code instances act as the specialized "hands" of the system. Each agent is a distinct process, invoked programmatically by the Orchestrator to perform a specific, well-defined task. These agents are defined using Claude Code's native sub-agent pattern, allowing each one to have a unique system prompt, toolset, and operational focus.

This model is a direct implementation of the "custom harness" or "scaffolding" pattern, an advanced workflow where a master script programmatically calls Claude Code to loop through a predefined list of tasks.7 By separating the high-level orchestration logic from the low-level task execution, the system achieves a clean separation of concerns, making it easier to debug, maintain, and extend.

### **1.2 The Five Phases of Automated Research**

The Helios Swarm operationalizes the research process into a structured, five-phase pipeline. This phased approach ensures a logical progression from a high-level query to a polished, well-reasoned final report.

* **Phase 1: Decompose:** The process begins when the user provides a high-level research prompt to the Orchestrator. The Orchestrator immediately delegates this prompt to a specialized Planner agent. The Planner's sole responsibility is to analyze the prompt and break it down into a structured series of smaller, answerable sub-questions. The output of this phase is a machine-readable task list (a JSON file), which becomes the master plan for the entire research operation. This initial planning step is critical and mirrors the "Explore \-\> Plan \-\> Code" workflow that Anthropic recommends for tackling complex problems, as it significantly improves the quality and coherence of the final output by ensuring a logical structure from the outset.7  
* **Phase 2: Allocate:** The Orchestrator script reads the tasks.json file generated by the Planner. It parses the list of sub-tasks and prepares the execution environment, creating necessary output directories and logging the plan. This phase serves as the setup step before initiating the parallel processing.  
* **Phase 3: Execute:** This is the core of the swarm's activity. The Orchestrator spawns a pool of Researcher agents in parallel, with the number of parallel agents configurable by the user. Each Researcher agent is assigned a single, unique sub-task from the plan. This parallel execution model leverages Claude Code's documented ability to run multiple instances simultaneously, dramatically accelerating the information-gathering process.12 Each agent works in complete isolation, reading its assigned task and writing its findings to a dedicated markdown file in an output directory.  
* **Phase 4: Synthesize:** Once all Researcher agents have completed their individual tasks and their output files have been generated, the Orchestrator invokes a single Synthesizer agent. This agent is provided with the entire collection of individual research outputs. Its task is to read, understand, and weave these disparate pieces of information into a single, coherent, and well-structured draft report, complete with logical sections and smooth transitions.  
* **Phase 5: Review:** The draft report is then passed to the final agent in the pipeline: the Critic. The Critic agent acts as an automated peer reviewer. It scrutinizes the synthesized document for logical fallacies, factual inconsistencies, structural weaknesses, and potential gaps in the research. The output of this phase is twofold: the final, polished report and a separate critique document that outlines the identified issues and suggestions for improvement. This automated review loop mimics the essential human process of critical evaluation and refinement.15

### **1.3 State Management and Communication: A File-Based Approach for Robustness**

A critical architectural decision in the Helios Swarm is the exclusive use of the local filesystem for all state management and inter-agent communication. Instead of relying on fragile in-memory data structures or complex messaging queues, the entire state of the research job is persisted to disk in a structured project directory. This includes the initial prompt, the JSON task list, the raw output from each Researcher agent, and the final synthesized report.

This design choice is based on the principle of **Durable Execution**. Agentic workflows, especially those involving deep research, can be long-running and resource-intensive, with some tasks taking hundreds of turns and consuming significant tokens.16 In such an environment, the system must be resilient to a variety of potential failures, including network interruptions, API rate limits, or transient errors in the Orchestrator script itself.17 A purely in-memory state management system would be wiped out by any such failure, forcing a costly and time-consuming restart from scratch.

By using the filesystem as the single source of truth, the Helios Swarm becomes inherently fault-tolerant and resumable. The Orchestrator is designed to be stateless; at any point, it can be stopped and restarted. Upon restart, it simply scans the project directory. By checking for the existence of tasks.json and the individual files in the output/ directory, it can determine exactly where the process was interrupted and resume from that point. If the planning phase was completed, it will not re-run it. If 7 out of 10 research tasks were completed, it will only launch agents for the remaining 3\. This approach is implicitly suggested by advanced Claude Code patterns that use markdown files as checklists or "scratchpads" to manage the state of complex, multi-step operations.8 This file-based architecture transforms the swarm from a transient, volatile process into a durable, persistent job that can reliably execute over extended periods.

### **1.4 Visualizing the Swarm: A Diagram of Agent Interaction and Data Flow**

The following diagram illustrates the flow of data and control within the Helios system, mapping directly to the five phases of research.

Code snippet

graph TD  
    A\[User Prompt\] \--\> B(Orchestrator: helios\_orchestrator.py);  
    B \-- "1. Decompose" \--\> C{Planner Agent};  
    C \-- "tasks.json" \--\> B;  
    B \-- "2. Allocate & 3\. Execute" \--\> D((Swarm of Researcher Agents));  
    subgraph Parallel Execution  
        D1  
        D2  
        D3  
    end  
    D \-- "task\_1.md, task\_2.md,..." \--\> E{Synthesizer Agent};  
    B \-- "4. Synthesize" \--\> E;  
    E \-- "draft\_report.md" \--\> F{Critic Agent};  
    B \-- "5. Review" \--\> F;  
    F \-- "final\_report.md & critique.md" \--\> G\[Final Output\];

    style C fill:\#cde4ff,stroke:\#6495ED,stroke-width:2px  
    style D fill:\#f9f,stroke:\#FF69B4,stroke-width:2px  
    style E fill:\#cde4ff,stroke:\#6495ED,stroke-width:2px  
    style F fill:\#cde4ff,stroke:\#6495ED,stroke-width:2px

## **Section 2: Forging the Agents: Mastering the Sub-Agent Pattern**

The intelligence of the Helios Swarm is not centralized in the Orchestrator but distributed across its team of specialized agents. This specialization is made possible by a core feature of Claude Code: the sub-agent pattern. This section provides a detailed examination of this pattern and delivers the complete, ready-to-deploy configurations for each agent in the Helios roster.

### **2.1 The Power of Specialization: An Overview of the Sub-Agent Pattern**

Claude Code's sub-agent feature allows developers to define specialized AI assistants as simple markdown files within a project's .claude/agents/ directory (or globally in \~/.claude/agents/). Each sub-agent is defined by three key components:

1. **Name:** A unique identifier.  
2. **Description:** A natural language explanation of the agent's purpose, which Claude Code uses to automatically delegate relevant tasks.  
3. **System Prompt:** A detailed set of instructions that defines the agent's persona, goals, constraints, and operational methodology.

This architecture enables the creation of a "mini-workforce" of experts, each fine-tuned for a specific task.19 When the main Claude Code process encounters a task that matches a sub-agent's description, it can delegate that task, providing a powerful mechanism for modularizing complex workflows.20

A primary architectural benefit of this pattern is **context preservation**. One of the most significant challenges in executing long, complex AI tasks is managing the model's limited context window and the associated token costs.12 Attempting to conduct a multi-step research project within a single, monolithic conversation would quickly pollute the context with irrelevant details, degrading performance and escalating costs. The sub-agent pattern is Anthropic's direct solution to this problem. As the official documentation states, "Each sub agent operates in its own context, preventing the main conversation from being polluted and keeping it focused on high-level objectives".

The Helios architecture leverages this feature not merely as a convenience but as a core strategic principle. By delegating each distinct phase of the research process to a specialized agent with its own fresh context window, the system can tackle complex, long-running research tasks that would otherwise be impractical or prohibitively expensive. The Orchestrator maintains the high-level state, while the agents operate in clean, focused, and cost-effective contexts.

### **2.2 The Helios Agent Roster**

The following are the complete implementations for the four specialized agents that constitute the Helios Swarm. To deploy the system, these markdown files must be created and placed in the .claude/agents/ directory within your project folder.

#### **The** planner-agent.md

This agent is the strategic mind of the swarm. It receives the user's high-level research prompt and deconstructs it into a concrete, actionable plan.

---

## **name: helios-planner description: "Takes a high-level research topic and breaks it down into a structured JSON list of specific, answerable sub-tasks." tools: Write**

You are an expert research strategist and project planner. Your sole purpose is to take a broad, high-level research prompt and decompose it into a series of specific, discrete, and answerable sub-questions.

Your process must be as follows:

1. **Analyze the Prompt:** Carefully read the user's research prompt. Identify the core subject, key entities, relationships, and the overall objective of the research.  
2. **Think Step-by-Step:** Formulate a logical plan of inquiry. What are the foundational concepts that need to be understood first? What are the subsequent areas of investigation? What comparative analyses or future implications should be explored?  
3. **Formulate Sub-Tasks:** Generate between 5 and 10 specific sub-tasks. Each sub-task should be a clear, self-contained question that a researcher could answer in a few paragraphs. Avoid overly broad or ambiguous questions.  
4. **Format as JSON:** Your final output MUST be a single, valid JSON object. This object should contain a single key, "research\_tasks", whose value is an array of strings. Each string in the array is one of the sub-tasks you have formulated.

Example Input Prompt:

"Analyze the impact of renewable energy on the global economy."

\*\*Example JSON Output:\*\*json

{

"research\_tasks":

}

Do not include any text or explanation outside of the final JSON object. Your entire response must be the raw JSON.

#### **The** researcher-agent.md

This agent is the information-gathering workhorse. Multiple instances of this agent run in parallel, each tackling one sub-task from the planner's list.

---

## **name: helios-researcher description: "Receives a single, specific research question and writes a detailed, factual, and well-reasoned answer. This agent performs the core research." tools: Write**

You are a diligent and objective research analyst. Your task is to take a single, highly specific research question and provide a comprehensive, factual, and well-reasoned answer.

Your instructions are as follows:

1. **Focus Exclusively:** Your entire response must focus ONLY on the single question provided to you. Do not stray into related topics or try to answer questions that were not asked.  
2. **Be Thorough:** Provide a detailed and comprehensive answer. Use your internal knowledge base to provide facts, figures, and established concepts related to the question.  
3. **Structure Your Answer:** Present your findings in clear, well-written prose. Use paragraphs to structure your response logically.  
4. **Maintain Objectivity:** Present information factually and avoid personal opinions or speculative language unless the question explicitly asks for analysis of future trends.  
5. **Output Format:** Your output should be a clean markdown text. Do not include a title or heading for your response. Simply begin writing the answer.

#### **The** synthesizer-agent.md

This agent acts as the master editor. It takes the fragmented outputs from the Researcher agents and weaves them into a single, cohesive narrative.

---

## **name: helios-synthesizer description: "Takes a collection of individual research text snippets and synthesizes them into a single, coherent, well-structured markdown document." tools: Write**

You are an expert editor and information synthesizer. You will be provided with a collection of raw text snippets, each answering a specific sub-question on a broader topic. Your task is to synthesize these disparate pieces into a single, cohesive, and well-structured report.

Your process must be as follows:

1. **Read and Understand All Inputs:** Carefully review all the provided text snippets to understand the full scope of the research.  
2. **Identify the Narrative Arc:** Determine the most logical flow for the information. Start with foundational concepts and build towards more complex or specific points.  
3. **Create Structure:** Organize the report with a clear hierarchy. Create a main title for the report. Use markdown headings (\#\#) and subheadings (\#\#\#) to create logical sections.  
4. **Rewrite and Integrate:** Do NOT simply concatenate the input snippets. You must rewrite and edit them to ensure a consistent tone and smooth transitions between sections. Paraphrase where necessary to avoid repetition and improve flow.  
5. **Synthesize, Do Not Invent:** Your task is to work exclusively with the information provided in the input snippets. Do not introduce any new facts, data, or opinions that were not present in the source texts. Your role is to structure and refine, not to conduct new research.  
6. **Final Output:** Your output should be a single, polished markdown document that reads as if it were written by a single author.

#### **The** critic-agent.md

This agent is the final quality gate. It performs a critical review of the synthesized draft, identifying weaknesses and areas for improvement.

---

## **name: helios-critic description: "Reviews a synthesized research document to identify logical fallacies, inconsistencies, and areas for improvement, providing a final critique." tools: Write**

You are a meticulous and critical academic reviewer. Your purpose is to analyze a provided research document and identify any weaknesses in its arguments, structure, and presentation. You are the final quality check.

Your review should focus on the following areas:

1. **Logical Coherence:** Does the document flow logically from one section to the next? Are there any contradictions or logical fallacies in the arguments presented?  
2. **Structural Integrity:** Is the document well-organized? Are the headings and subheadings appropriate? Is the introduction clear and the conclusion well-supported by the body of the text?  
3. **Completeness and Gaps:** Based on the topic, are there any obvious gaps in the information presented? Does the document fail to address any critical aspects of the subject?  
4. **Clarity and Precision:** Is the language clear and unambiguous? Are there any vague statements or unsupported claims?

Your output must be a markdown document with two distinct sections:

1. **A "Final Critique" Section:** Begin with the heading \#\# Final Critique. In this section, provide a bulleted list of your findings. For each point, clearly and constructively state the issue you identified.  
2. **The "Revised Report" Section:** Following the critique, include a horizontal rule (\---). Then, paste the ENTIRE original document, incorporating any minor revisions (like fixing typos or minor grammatical errors) that you can make directly. Major structural or logical changes should be noted in the critique section above.

Your goal is not to be overly negative, but to provide constructive feedback that would improve the quality and reliability of the final report.

### **Table 2.1: Sub-Agent Role Definitions and Configurations**

This table provides a consolidated overview of the Helios agentic workforce, defining the role, implementation, and data contracts for each component.

| Agent Name | Filename | Role/Responsibility | System Prompt Summary | Expected Input | Expected Output Format |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **Planner** | planner-agent.md | Deconstructs the high-level prompt into a structured plan. | Acts as an expert research strategist, breaking a broad topic into 5-10 specific questions. | The user's initial natural language research prompt. | A single, valid JSON object with a research\_tasks key containing an array of strings. |
| **Researcher** | researcher-agent.md | Gathers information by answering a single, specific question. | Acts as a diligent analyst, focusing exclusively on the provided question and delivering a thorough, factual answer. | A single string containing one research question from the tasks.json file. | A clean markdown text snippet containing the answer. No title or headings. |
| \*\*Synthesizer\` | synthesizer-agent.md | Weaves individual research snippets into a coherent report. | Acts as an expert editor, structuring, rewriting, and integrating multiple text inputs into a unified document. | A single text block containing all concatenated outputs from the Researcher agents. | A single, polished markdown document with a title and appropriate headings. |
| **Critic** | critic-agent.md | Reviews the synthesized draft for quality and logical consistency. | Acts as a critical academic reviewer, identifying flaws, gaps, and areas for improvement in the draft report. | The full markdown text of the synthesized draft report. | A markdown document with two sections: a bulleted list under \#\# Final Critique and the revised report. |

## **Section 3: The Orchestrator: The Python Script at the Heart of the Swarm**

The Helios Swarm's operations are directed by a central orchestration script. While simple workflows can be managed with shell scripts, the complexity of managing a dynamic, parallel swarm with robust state tracking and error handling necessitates a more powerful, high-level programming language. This section justifies the selection of Python, details the design of the script's command-line interface, and provides the complete, annotated source code for the orchestrator.

### **3.1 The Right Tool for the Job: Why Python over Bash for Orchestration**

While Bash is a powerful tool for simple command-line piping and chaining executables, it falls short when faced with the requirements of a sophisticated orchestration system like Helios.22 The decision to use Python is a strategic one, grounded in the understanding that

**orchestration is a software engineering problem, not a shell scripting problem.**

A simple Bash script could chain a few claude \-p commands together. However, the Helios Orchestrator must perform tasks that are cumbersome in Bash but trivial in Python:

* **Complex Data Structures:** The orchestrator must parse the JSON output from the Planner agent and manage the list of tasks. Python's native support for JSON and rich data structures makes this straightforward, whereas Bash would require external tools like jq and complex string manipulation.24  
* **Robust Error Handling:** Python's try...except blocks provide a structured way to handle errors, such as a failed subprocess or a malformed JSON file. This allows the orchestrator to gracefully manage failures in one agent without crashing the entire system, a critical feature for a long-running process.23  
* **Parallel Process Management:** Launching, monitoring, and collecting results from a dynamic number of parallel processes is a complex task. Python's concurrent.futures module provides a high-level, clean abstraction for managing a pool of processes, simplifying the most complex part of the swarm's operation.25  
* **Maintainability and Scalability:** As the system grows, Python's modular structure, functions, and object-oriented capabilities make the code easier to read, maintain, and extend compared to a large, monolithic shell script.27

The existence of an official Python SDK for Claude Code further signals that Python is the intended and supported language for building complex, programmatic integrations.28

### **3.2 Designing the Command-Line Interface with** argparse

To ensure the Helios Orchestrator is both powerful and user-friendly, its command-line interface is built using Python's standard argparse module. This module simplifies the process of defining arguments, parsing them from the command line, and automatically generating helpful usage messages.30 The interface is designed to be clear and flexible, requiring only the research prompt to run but allowing for customization of key parameters.

### **Table 3.1: Orchestrator Script CLI Arguments**

This table serves as the user manual for the helios\_orchestrator.py script, detailing all available command-line options.

| Argument | Shorthand | help Text | type | required | Default Value |
| :---- | :---- | :---- | :---- | :---- | :---- |
| \--prompt | \-p | The high-level research prompt to initiate the swarm. | str | True | None |
| \--project\_name | \-n | A name for the project directory where all files will be stored. | str | True | None |
| \--model | \-m | The Claude model to use for the agents (e.g., 'claude-3-5-sonnet-20240620'). | str | False | claude-3-5-sonnet-20240620 |
| \--max\_workers | \-w | The maximum number of parallel Researcher agents to run. | int | False | 4 |
| \--force\_rerun | \-f | Force re-running all phases, even if output files exist. | bool (action='store\_true') | False | False |

### **3.3 Core Logic: A Step-by-Step Breakdown of the Orchestration Process**

The main execution flow of helios\_orchestrator.py directly implements the five-phase architecture. The script begins by parsing the command-line arguments. It then sets up the project directory structure, ensuring that folders for output and synthesis exist.

The core logic proceeds sequentially through each phase:

1. **Decomposition:** It checks if a tasks.json file already exists. If not (or if \--force\_rerun is specified), it invokes the planner-agent via a subprocess call to the claude CLI, passing the user's prompt. The output is captured and saved to tasks.json.  
2. **Allocation & Execution:** The script reads the tasks from tasks.json. It then uses the ProcessPoolExecutor to launch the Researcher agents in parallel.  
3. **Synthesis:** After all research tasks are complete, it checks for the existence of draft\_report.md. If needed, it concatenates all the individual research outputs and passes them to the synthesizer-agent.  
4. **Review:** Finally, it takes the draft report and passes it to the critic-agent to produce the final report and critique.

### **3.4 Managing the Swarm: Parallel Execution with** concurrent.futures.ProcessPoolExecutor

The heart of the swarm's efficiency lies in its parallel execution of research tasks. This is achieved using Python's concurrent.futures.ProcessPoolExecutor. This high-level interface is the ideal choice for this use case for several reasons:

* **Bypasses the GIL:** Unlike ThreadPoolExecutor, ProcessPoolExecutor uses separate processes instead of threads. This allows it to bypass Python's Global Interpreter Lock (GIL) and achieve true parallelism on multi-core machines, which is essential since each agent is an independent, external process.25  
* **Simplified Interface:** It provides a much simpler API than the lower-level multiprocessing module. The executor.map function elegantly applies a single function (run\_research\_task) to an iterable (the list of tasks), automatically managing the process pool, distributing the work, and collecting the results.33  
* **Robustness:** The process pool isolates failures. If one Researcher agent fails for some reason, it will not bring down the entire orchestrator script, allowing the other agents to continue their work.35

The orchestrator script will create a ProcessPoolExecutor with a number of workers specified by the \--max\_workers argument. It will then call executor.map, which will non-blockingly distribute the research tasks across the worker processes, providing a simple yet powerful mechanism for managing the swarm.

### **3.5 The Complete** helios\_orchestrator.py **Script**

The following is the complete, annotated Python script that serves as the Helios Orchestrator. It integrates all the concepts discussed: argparse for the CLI, subprocess for invoking Claude Code agents, json for state management, and concurrent.futures for parallel execution.

Python

\#\!/usr/bin/env python3  
import argparse  
import json  
import os  
import subprocess  
import logging  
from concurrent.futures import ProcessPoolExecutor, as\_completed  
from pathlib import Path

\# \--- Configuration \---  
\# Setup basic logging  
logging.basicConfig(level=logging.INFO, format\='%(asctime)s \- %(levelname)s \- %(message)s')

\# Define file paths  
AGENTS\_DIR \= ".claude/agents"  
PLANNER\_AGENT\_MD \= "helios-planner.md"  
RESEARCHER\_AGENT\_MD \= "helios-researcher.md"  
SYNTHESIZER\_AGENT\_MD \= "helios-synthesizer.md"  
CRITIC\_AGENT\_MD \= "helios-critic.md"

\# \--- Helper Functions \---  
def run\_claude\_agent(agent\_name: str, prompt\_data: str, project\_path: Path, model: str) \-\> str:  
    """  
    Invokes a specified Claude Code sub-agent via the CLI as a subprocess.

    Args:  
        agent\_name (str): The name of the agent to use (e.g., 'helios-planner').  
        prompt\_data (str): The input prompt data for the agent.  
        project\_path (Path): The root path of the research project.  
        model (str): The Claude model to use.

    Returns:  
        str: The stdout from the Claude Code process.  
    """  
    command \= \[  
        "claude",  
        "-p",  
        f"Use the {agent\_name} agent. Here is the data:\\n\\n{prompt\_data}",  
        "--model", model  
    \]  
    logging.info(f"Executing command: {' '.join(command)}")  
    try:  
        \# We use subprocess.run to execute the claude CLI command.  
        \# The command is executed from the project\_path directory to ensure  
        \# that Claude Code can find the.claude/agents/ configuration.  
        \# We capture stdout and check for errors.  
        result \= subprocess.run(  
            command,  
            cwd=project\_path,  
            capture\_output=True,  
            text=True,  
            check=True,  
            encoding='utf-8'  
        )  
        logging.info(f"Agent '{agent\_name}' completed successfully.")  
        return result.stdout  
    except subprocess.CalledProcessError as e:  
        logging.error(f"Error running agent '{agent\_name}': {e}")  
        logging.error(f"Stderr: {e.stderr}")  
        raise  
    except FileNotFoundError:  
        logging.error("'claude' command not found. Is Claude Code installed and in your PATH?")  
        raise

def run\_research\_task(task\_info: dict, project\_path: Path, model: str) \-\> Path:  
    """  
    Wrapper function for a single research task, designed to be run in a parallel process.

    Args:  
        task\_info (dict): A dictionary containing 'task\_index' and 'task\_description'.  
        project\_path (Path): The root path of the research project.  
        model (str): The Claude model to use.

    Returns:  
        Path: The path to the generated output file.  
    """  
    task\_index \= task\_info\['task\_index'\]  
    task\_description \= task\_info\['task\_description'\]  
    output\_path \= project\_path / "output" / f"task\_{task\_index \+ 1}\_output.md"

    logging.info(f"Starting research task {task\_index \+ 1}: {task\_description}")  
    try:  
        research\_output \= run\_claude\_agent(  
            "helios-researcher",  
            task\_description,  
            project\_path,  
            model  
        )  
        with open(output\_path, "w", encoding='utf-8') as f:  
            f.write(research\_output)  
        logging.info(f"Finished research task {task\_index \+ 1}. Output saved to {output\_path}")  
        return output\_path  
    except Exception as e:  
        logging.error(f"Research task {task\_index \+ 1} failed: {e}")  
        \# Write an error file to indicate failure  
        error\_path \= project\_path / "output" / f"task\_{task\_index \+ 1}\_error.txt"  
        with open(error\_path, "w", encoding='utf-8') as f:  
            f.write(str(e))  
        raise

\# \--- Main Orchestration Logic \---  
def main(args):  
    """The main function to orchestrate the Helios Research Swarm."""  
    project\_path \= Path(args.project\_name)  
    output\_path \= project\_path / "output"  
    synthesis\_path \= project\_path / "synthesis"

    \# \--- Setup Project Directory \---  
    logging.info(f"Setting up project directory: {project\_path}")  
    project\_path.mkdir(exist\_ok=True)  
    output\_path.mkdir(exist\_ok=True)  
    synthesis\_path.mkdir(exist\_ok=True)  
      
    \# Verify that agent definitions exist  
    for agent\_md in:  
        if not (project\_path / AGENTS\_DIR / agent\_md).exists():  
            logging.error(f"Agent definition not found: {project\_path / AGENTS\_DIR / agent\_md}")  
            logging.error("Please ensure all agent.md files are in the.claude/agents/ directory.")  
            return

    \# \--- Phase 1: Decompose (Planning) \---  
    tasks\_json\_path \= project\_path / "tasks.json"  
    if not tasks\_json\_path.exists() or args.force\_rerun:  
        logging.info("Phase 1: Decomposing prompt with Planner Agent.")  
        planner\_output \= run\_claude\_agent(  
            "helios-planner",  
            args.prompt,  
            project\_path,  
            args.model  
        )  
        try:  
            \# The planner agent is instructed to output only JSON.  
            tasks\_data \= json.loads(planner\_output)  
            with open(tasks\_json\_path, "w", encoding='utf-8') as f:  
                json.dump(tasks\_data, f, indent=2)  
            logging.info(f"Planner agent finished. Task list saved to {tasks\_json\_path}")  
        except json.JSONDecodeError:  
            logging.error("Planner agent did not return valid JSON. Saving raw output for debugging.")  
            with open(project\_path / "planner\_error\_output.txt", "w", encoding='utf-8') as f:  
                f.write(planner\_output)  
            return  
    else:  
        logging.info("Phase 1: Skipping planning, tasks.json already exists.")

    with open(tasks\_json\_path, "r", encoding='utf-8') as f:  
        research\_tasks \= json.load(f).get("research\_tasks",)  
      
    if not research\_tasks:  
        logging.error("No research tasks found in tasks.json. Aborting.")  
        return

    \# \--- Phase 2 & 3: Allocate & Execute (Research) \---  
    logging.info(f"Phase 2 & 3: Allocating and executing {len(research\_tasks)} research tasks in parallel.")  
    tasks\_to\_run \=  
    for i, task\_desc in enumerate(research\_tasks):  
        task\_output\_file \= output\_path / f"task\_{i \+ 1}\_output.md"  
        if not task\_output\_file.exists() or args.force\_rerun:  
            tasks\_to\_run.append({'task\_index': i, 'task\_description': task\_desc})  
        else:  
            logging.info(f"Skipping research task {i+1}, output file already exists.")  
      
    if tasks\_to\_run:  
        \# We use ProcessPoolExecutor to run research tasks in parallel.  
        \# This is ideal for I/O-bound or external process tasks like calling the claude CLI.  
        with ProcessPoolExecutor(max\_workers=args.max\_workers) as executor:  
            \# Create a dictionary of futures to track progress  
            future\_to\_task \= {executor.submit(run\_research\_task, task, project\_path, args.model): task for task in tasks\_to\_run}  
            for future in as\_completed(future\_to\_task):  
                task \= future\_to\_task\[future\]  
                try:  
                    future.result()  
                except Exception as exc:  
                    logging.error(f'Task {task\["task\_index"\] \+ 1} generated an exception: {exc}')  
    else:  
        logging.info("All research tasks have already been completed.")

    \# \--- Phase 4: Synthesize \---  
    draft\_report\_path \= synthesis\_path / "draft\_report.md"  
    if not draft\_report\_path.exists() or args.force\_rerun:  
        logging.info("Phase 4: Synthesizing research outputs with Synthesizer Agent.")  
        all\_research\_outputs \=  
        for i in range(len(research\_tasks)):  
            task\_output\_file \= output\_path / f"task\_{i \+ 1}\_output.md"  
            if task\_output\_file.exists():  
                with open(task\_output\_file, "r", encoding='utf-8') as f:  
                    all\_research\_outputs.append(f"--- Snippet from Task {i+1} \---\\n\\n{f.read()}")  
          
        if all\_research\_outputs:  
            combined\_input \= "\\n\\n".join(all\_research\_outputs)  
            synthesized\_output \= run\_claude\_agent(  
                "helios-synthesizer",  
                combined\_input,  
                project\_path,  
                args.model  
            )  
            with open(draft\_report\_path, "w", encoding='utf-8') as f:  
                f.write(synthesized\_output)  
            logging.info(f"Synthesizer agent finished. Draft report saved to {draft\_report\_path}")  
        else:  
            logging.warning("No research outputs found to synthesize.")  
    else:  
        logging.info("Phase 4: Skipping synthesis, draft\_report.md already exists.")

    \# \--- Phase 5: Review \---  
    final\_report\_path \= project\_path / "final\_report.md"  
    final\_critique\_path \= synthesis\_path / "final\_critique.md"  
    if (not final\_report\_path.exists() and not final\_critique\_path.exists()) or args.force\_rerun:  
        if draft\_report\_path.exists():  
            logging.info("Phase 5: Reviewing draft with Critic Agent.")  
            with open(draft\_report\_path, "r", encoding='utf-8') as f:  
                draft\_content \= f.read()  
              
            critic\_output \= run\_claude\_agent(  
                "helios-critic",  
                draft\_content,  
                project\_path,  
                args.model  
            )  
              
            \# The critic agent outputs both critique and the revised report, separated by '---'  
            parts \= critic\_output.split('\\n---\\n', 1)  
            if len(parts) \== 2:  
                critique, final\_report \= parts  
                with open(final\_critique\_path, "w", encoding='utf-8') as f:  
                    f.write(critique)  
                with open(final\_report\_path, "w", encoding='utf-8') as f:  
                    f.write(final\_report)  
                logging.info(f"Critic agent finished. Final report saved to {final\_report\_path} and critique to {final\_critique\_path}")  
            else:  
                logging.warning("Critic agent output was not in the expected format. Saving raw output.")  
                with open(synthesis\_path / "critic\_raw\_output.md", "w", encoding='utf-8') as f:  
                    f.write(critic\_output)  
        else:  
            logging.warning("No draft report found to review.")  
    else:  
        logging.info("Phase 5: Skipping review, final report already exists.")

    logging.info("Helios Research Swarm has completed its work.")

if \_\_name\_\_ \== "\_\_main\_\_":  
    \# Setup argparse for a clean command-line interface  
    parser \= argparse.ArgumentParser(  
        description="Helios Research Swarm: An automated research agent using Claude Code.",  
        formatter\_class=argparse.ArgumentDefaultsHelpFormatter  
    )  
    parser.add\_argument(  
        "-p", "--prompt",  
        required=True,  
        help\="The high-level research prompt to initiate the swarm."  
    )  
    parser.add\_argument(  
        "-n", "--project\_name",  
        required=True,  
        help\="A unique name for the project directory where all files will be stored."  
    )  
    parser.add\_argument(  
        "-m", "--model",  
        default="claude-3-5-sonnet-20240620",  
        help\="The Claude model to use for the agents."  
    )  
    parser.add\_argument(  
        "-w", "--max\_workers",  
        type\=int,  
        default=4,  
        help\="The maximum number of parallel Researcher agents to run."  
    )  
    parser.add\_argument(  
        "-f", "--force\_rerun",  
        action="store\_true",  
        help\="Force re-running all phases, even if output files exist."  
    )

    cli\_args \= parser.parse\_args()  
    main(cli\_args)

## **Section 4: Deployment and Operation: A Practical Field Guide**

With the architecture defined and the orchestrator script written, this section provides a practical guide to deploying and operating the Helios Research Swarm. It covers the necessary environmental prerequisites, project setup, a sample execution walkthrough, and critical considerations for managing cost and security in an automated environment.

### **4.1 Environment Setup: Prerequisites and Dependencies**

Before deploying the Helios Swarm, the target environment must be correctly configured with all necessary software and credentials.

* **System Requirements:**  
  1. **Operating System:** A Unix-like environment is required. macOS 10.15+, Ubuntu 20.04+, or Debian 10+ are officially supported. Windows users can leverage the Windows Subsystem for Linux (WSL).1  
  2. **Node.js:** Version 18 or newer is essential for running the Claude Code CLI.1  
  3. **Python:** Version 3.10 or newer is required for the helios\_orchestrator.py script.28  
  4. **Git:** While not strictly required by the script itself, Git is a standard part of any development environment and recommended for managing the project files.1  
* **Anthropic Account and Authentication:**  
  1. Access to Claude Code is not free. A subscription to a **Claude Pro or Max plan**, or an **Anthropic API key with active billing** is required.37 The orchestrator script assumes you have authenticated the Claude Code CLI with your account.  
* **Software Installation:**  
  1. **Install Claude Code CLI:** The primary dependency is the Claude Code command-line tool, which is installed globally via npm:  
  2. Bash

npm install \-g @anthropic-ai/claude-code

3.   
   4. It is crucial *not* to use sudo for this installation to avoid permission issues.1  
   5. **Authenticate Claude Code:** After installation, run claude once in your terminal to complete the one-time authentication process.1  
   6. **Install Python Dependencies:** The orchestrator script does not have external Python library dependencies beyond the standard library, so no pip install commands are necessary for its core functionality.

### **4.2 Project Initialization and Directory Structure**

To begin a new research task, a project directory must be set up with the correct structure. This ensures that the orchestrator can find the agent definitions and knows where to store state and output files.

1. Create a main directory for your research project (e.g., mkdir quantum\_cryptography\_research).  
2. Inside this directory, create the subdirectory for agent definitions: mkdir \-p.claude/agents.  
3. Copy the four agent markdown files (planner-agent.md, researcher-agent.md, synthesizer-agent.md, critic-agent.md) into the .claude/agents/ directory.  
4. Copy the helios\_orchestrator.py script into the main project directory.

Your initial project structure should look like the one detailed in the following table.

### **Table 4.1: Helios Project Directory Structure**

This table provides a canonical map of the filesystem layout for a Helios project. This standardized structure makes the system's state predictable and easy to navigate.

| Path | Description |
| :---- | :---- |
| research\_project/ | The root directory for a single research task. |
| ├──.claude/ | Hidden directory for Claude Code configurations. |
| │ └── agents/ | Contains the markdown definitions for all specialized sub-agents. |
| │ ├── planner-agent.md | The Planner agent's configuration file. |
| │ ├── researcher-agent.md | The Researcher agent's configuration file. |
| │ ├── synthesizer-agent.md | The Synthesizer agent's configuration file. |
| │ └── critic-agent.md | The Critic agent's configuration file. |
| ├── helios\_orchestrator.py | The main Python script that drives the swarm. |
| ├── tasks.json | **Generated File:** Stores the JSON output from the Planner agent. |
| ├── output/ | **Generated Directory:** Contains the raw markdown outputs from each Researcher agent. |
| │ ├── task\_1\_output.md | **Generated File:** Output from the first research task. |
| │ └──... |  |
| ├── synthesis/ | **Generated Directory:** Contains intermediate and final outputs from the synthesis and review phases. |
| │ ├── draft\_report.md | **Generated File:** The initial report created by the Synthesizer agent. |
| │ └── final\_critique.md | **Generated File:** The critique document produced by the Critic agent. |
| └── final\_report.md | **Generated File:** The final, polished research report. |

### **4.3 Execution Walkthrough: From Initial Prompt to Final Report**

Once the project is set up, initiating the swarm is done with a single command. For example, to research the impact of quantum computing on modern cryptography, you would navigate to your project directory and run:

Bash

python helios\_orchestrator.py \\  
    \--prompt "Analyze the impact of quantum computing on modern cryptography, including current vulnerabilities and emerging quantum-resistant algorithms." \\  
    \--project\_name "quantum\_crypto\_report"

The orchestrator will then begin its work, providing real-time logging to the console:

2025-08-15 10:00:00 \- INFO \- Setting up project directory: quantum\_crypto\_report  
2025-08-15 10:00:01 \- INFO \- Phase 1: Decomposing prompt with Planner Agent.  
2025-08-15 10:00:01 \- INFO \- Executing command: claude \-p "Use the helios-planner agent..."...  
2025-08-15 10:00:45 \- INFO \- Planner agent finished. Task list saved to quantum\_crypto\_report/tasks.json  
2025-08-15 10:00:46 \- INFO \- Phase 2 & 3: Allocating and executing 7 research tasks in parallel.  
2025-08-15 10:00:47 \- INFO \- Starting research task 1: What is Shor's algorithm and how does it threaten RSA and ECC encryption?  
2025-08-15 10:00:47 \- INFO \- Starting research task 2:...  
...  
2025-08-15 10:05:12 \- INFO \- Finished research task 1\. Output saved to quantum\_crypto\_report/output/task\_1\_output.md  
...  
2025-08-15 10:10:00 \- INFO \- All research tasks have been completed.  
2025-08-15 10:10:01 \- INFO \- Phase 4: Synthesizing research outputs with Synthesizer Agent.  
...  
2025-08-15 10:12:30 \- INFO \- Synthesizer agent finished. Draft report saved to quantum\_crypto\_report/synthesis/draft\_report.md  
2025-08-15 10:12:31 \- INFO \- Phase 5: Reviewing draft with Critic Agent.  
...  
2025-08-15 10:14:00 \- INFO \- Critic agent finished. Final report saved to quantum\_crypto\_report/final\_report.md and critique to quantum\_crypto\_report/synthesis/final\_critique.md  
2025-08-15 10:14:00 \- INFO \- Helios Research Swarm has completed its work.

Upon completion, the quantum\_crypto\_report directory will contain all the generated artifacts, with final\_report.md being the primary deliverable.

### **4.4 Managing Costs and Security in an Automated Environment**

Deploying an automated AI system requires diligent attention to both cost control and security.

Cost Management:

Automated agentic workflows can consume a significant number of tokens, and costs can escalate quickly if not managed. The average daily cost for an interactive Claude Code user is around $6, but this can be much higher for intensive automation.21

* **Monitoring:** The orchestrator script logs the start and end of each agent's task. For precise cost tracking, the script could be modified to use the \--output-format json flag when calling the claude CLI. The resulting JSON contains cost information that can be logged and aggregated.28 Tools also exist to analyze the conversation logs stored in  
   \~/.claude/projects/ to visualize costs.40  
* **Model Selection:** The \--model flag is a powerful lever for cost control. For the Planner and Researcher agents, a more cost-effective model like Claude 3.5 Sonnet may be sufficient. For the more nuanced tasks of the Synthesizer and Critic, a more powerful (and expensive) model like Claude 3 Opus might yield better results. This tactical model selection can optimize the cost-performance ratio.12  
* **Architectural Efficiency:** The core architecture of the Helios swarm, with its specialized, single-task agents, is itself a primary cost-control mechanism. It avoids the massive token consumption associated with maintaining a long, bloated context window across a multi-step task (see Section 2.1).

Security:

An automated script with the ability to execute commands and write to the filesystem presents a potential security risk. While convenient for interactive use, flags like \--dangerously-skip-permissions are entirely inappropriate for an unattended, automated system like Helios.43 A much more secure approach is to enforce the

**Principle of Least Privilege**.

This principle dictates that each component of a system should only be granted the permissions absolutely necessary for it to perform its designated function. Claude Code's permission system is designed to support this. Instead of granting blanket permissions, the orchestrator script should be modified to use the \--allowedTools flag to provide fine-grained control for each agent invocation.7

For example:

* The Planner agent only needs to write to tasks.json. Its invocation could be restricted to claude... \--allowedTools "Write(path:tasks.json)".  
* A Researcher agent only needs to write to its specific output file (e.g., task\_1\_output.md). Its invocation could be restricted to claude... \--allowedTools "Write(path:output/task\_1\_output.md)".  
* If a future version of the Researcher used a web search tool, its permissions could be claude... \--allowedTools "Write(path:output/task\_1\_output.md),WebFetchTool(domain:\*)".

This granular approach dramatically reduces the system's attack surface. If an agent were to be compromised or behave unexpectedly, its ability to cause harm would be strictly confined to its pre-approved permissions, preventing it from modifying arbitrary files or executing dangerous shell commands.1 This is the professional and secure way to manage permissions in a headless, agentic system.

## **Section 5: Conclusion and Future Horizons**

The Helios Research Swarm demonstrates a powerful and practical application of agentic AI, moving beyond simple chat interactions to automate complex, multi-step cognitive workflows. By combining the headless capabilities of the Claude Code CLI, the modularity of the sub-agent pattern, and the robust control of a Python orchestrator, Helios provides a blueprint for building scalable and durable AI-powered research systems. It effectively operationalizes the most advanced usage patterns documented by Anthropic, transforming a high-level natural language query into a comprehensive, structured, and critically reviewed research document.

### **5.1 Summary of the Helios Swarm's Capabilities**

The system as designed offers a robust solution for automated research. It successfully:

* **Decomposes Complexity:** The Planner agent effectively breaks down ambiguous, high-level prompts into a concrete and actionable research plan.  
* **Executes in Parallel:** The swarm of Researcher agents dramatically accelerates the information-gathering phase through concurrent execution.  
* **Synthesizes Coherently:** The Synthesizer and Critic agents work in tandem to transform raw data points into a polished and logically sound narrative.  
* **Maintains Robust State:** The file-based architecture ensures that the entire process is fault-tolerant and resumable, making it suitable for long-running, unattended tasks.  
* **Provides a Configurable Framework:** The system is not a black box. Through CLI arguments and easily editable sub-agent definitions, users can control the models used, the degree of parallelism, and the specific "personalities" of the agents.

### **5.2 Pathways for Enhancement**

While powerful, the current implementation of the Helios Swarm serves as a foundational platform. Several clear pathways exist for significant future enhancements, primarily through the integration of more advanced tooling and deployment strategies.

* **Integrating MCP Tools for Live Web Research:** The most impactful enhancement would be to equip the Researcher agent with live web access. The current implementation relies on the model's internal knowledge. By integrating a Model Context Protocol (MCP) server for browser automation, such as one using **Playwright** or **Puppeteer**, the Researcher could perform real-time web searches, read articles, and scrape data.44 This would vastly improve the timeliness and depth of the research, allowing the swarm to analyze current events and access information beyond the model's training cut-off. The Orchestrator would be modified to launch the MCP server and provide the  
   Researcher agents with the necessary permissions (e.g., \--allowedTools "mcp\_\_puppeteer\_\_navigate,mcp\_\_puppeteer\_\_screenshot").1  
* **Persistent VM Deployment for 24/7 Operation:** To transform Helios from a script into a true autonomous service, it could be deployed on a persistent cloud virtual machine (e.g., an AWS EC2 instance or a Digital Ocean droplet).48 Using a terminal multiplexer like  
   screen or zellij, the orchestrator could be launched in a detached session, allowing it to run long research jobs for hours or days, completely independent of the user's local machine.48 This would enable "fire-and-forget" research tasks, with the system potentially configured to send a notification (e.g., via a custom hook or another MCP tool) upon completion.  
* **Advanced Error Handling and Retries:** The current Python script has basic error handling. A more production-grade version would implement more sophisticated resilience patterns. This could include automatic retries with exponential backoff for transient network or API errors, a standard practice for building robust distributed systems.49 If an agent fails after several retries, the system could be configured to flag the failed task and continue with the rest of the research, rather than halting completely.  
* **Iterative Refinement Loop:** The current workflow ends with the Critic agent's review. A more advanced, self-correcting system could be created by adding an iterative loop. In this model, the final\_critique.md would be fed back to the Synthesizer agent along with the original draft, with the prompt "Revise the report to address these critical points." This loop could continue until the Critic agent reviews the document and generates an empty critique, signifying that the report has met the required quality standard. This would create a truly autonomous cycle of drafting, reviewing, and refining.

